# SFARI Read Data
The reads GraphQL API is used to organize the aggregated mini-bams and sqlite3 database generated by the [SFARI readviz pipeline](https://github.com/leklab/sfari-readviz). It maps a variant of interest to a bam containing example heterozygous, hemizygous (where applicable) and homozygous variants from exome and genome data. This is done through clevely labelling these examples using read group. The read data only shows the surround 50 bp so is not at risk of releasing individual genotypes.

## nginx configuration
The `/readviz` directory needs to configured in nginx so that it can serve files that can be accessed by web browser and IGV js plugin. An [example ngix configuration](https://github.com/leklab/sfari_browser/blob/master/misc/sfari-browser).

## Reference data
### Reference sequence
The following files are used for the reference sequence:
- GRCh37: `gs://gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta`
- GRCh38: `gs://gcp-public-data--broad-references/hg38/v0/Homo_sapiens_assembly38.fasta`

### Location on server
The files are hosted in the `/readviz/reference` directory on the server and accessible via the following URL:
* [GRCh37](https://genomes.sfari.org/readviz/reference/Homo_sapiens_assembly19.fasta)
* [GRCh38](https://genomes.sfari.org/readviz/reference/Homo_sapiens_assembly38.fasta)

## Reads data
The aggregated read data is organized in the following directory structure.
* `/readviz/spark_exome`
* `/readviz/spark_wgs`
* `/readviz/ssc_wgs`

In each of these directories there is one sqlite3 database file for each chromosome. There is multiple aggregated mini-bams per chromosome. This was partition by the number of samples and also breaking each chromosomes into equal sized intervals.






